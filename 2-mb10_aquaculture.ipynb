{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b211a17e-111c-4423-ab5f-bbe123f785b5",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f141f91b-09c0-495b-9920-077b75fa0eb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T15:14:54.892179Z",
     "iopub.status.busy": "2025-05-15T15:14:54.891732Z",
     "iopub.status.idle": "2025-05-15T15:14:59.644535Z",
     "shell.execute_reply": "2025-05-15T15:14:59.643851Z",
     "shell.execute_reply.started": "2025-05-15T15:14:54.892151Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import tensorflow as tf\n",
    "import ee\n",
    "import numpy as np\n",
    "from osgeo import ogr\n",
    "from osgeo import gdal\n",
    "import glob,pygeoj\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from patchify import patchify, unpatchify\n",
    "\n",
    "\n",
    "import json\n",
    "import math\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "import folium\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "logging.getLogger('googleapicliet.discovery_cache').setLevel(logging.ERROR)\n",
    "\n",
    "gpu_dict    = {'4090':{'GPU_AFFINTY' : 0, 'GPU_MEMORY_LIMIT_GB':12}}\n",
    "sel_gpu     = '4090'\n",
    "GPU_AFFINTY = gpu_dict[sel_gpu]['GPU_AFFINTY'] \n",
    "GPU_MEMORY_LIMIT_GB = gpu_dict[sel_gpu]['GPU_MEMORY_LIMIT_GB']\n",
    "USER_EE_PROJECT='USER_PROJECT_ID'\n",
    "\n",
    "try:\n",
    "    ee.Initialize(project = USER_EE_PROJECT)\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project = USER_EE_PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da72608-f60c-4060-ad8e-a9a5a49a047a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T15:15:03.793986Z",
     "iopub.status.busy": "2025-05-15T15:15:03.793314Z",
     "iopub.status.idle": "2025-05-15T15:15:03.935220Z",
     "shell.execute_reply": "2025-05-15T15:15:03.934850Z",
     "shell.execute_reply.started": "2025-05-15T15:15:03.793948Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.15.0\n",
      "Folium Version: 0.14.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "EE_TILES = 'https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}'\n",
    "\n",
    "print('Tensorflow Version:',tf.__version__)\n",
    "print('Folium Version:',folium.__version__)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[GPU_AFFINTY], 'GPU')\n",
    "    GPU_MEMORY_LIMIT_GB = GPU_MEMORY_LIMIT_GB * 1e3\n",
    "    if GPU_MEMORY_LIMIT_GB == 0:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    else:\n",
    "        tf.config.set_logical_device_configuration(gpus[GPU_AFFINTY],[tf.config.LogicalDeviceConfiguration(memory_limit=GPU_MEMORY_LIMIT_GB)])\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af202f17-7c68-441f-b731-6bd5031eeda9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T15:15:06.262752Z",
     "iopub.status.busy": "2025-05-15T15:15:06.262520Z",
     "iopub.status.idle": "2025-05-15T15:15:06.266093Z",
     "shell.execute_reply": "2025-05-15T15:15:06.265503Z",
     "shell.execute_reply.started": "2025-05-15T15:15:06.262733Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_directory(new_folder):\n",
    "  ''' Check if any of the specified folder already exist'''\n",
    "  if not os.path.exists(new_folder):\n",
    "      print(f'lets make the directory: {new_folder}')\n",
    "      os.makedirs(new_folder)\n",
    "  else: return\n",
    "\n",
    "  def check_file_exists(paths):\n",
    "    \"\"\"Check if any of the specified paths already exist\"\"\"\n",
    "    for path in paths:\n",
    "        if os.path.exists(path):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a873c34b-2040-4ccf-9d57-4147c460907b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ENV Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e4a964-948e-4632-be0d-92de58891eb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T15:15:08.667398Z",
     "iopub.status.busy": "2025-05-15T15:15:08.667121Z",
     "iopub.status.idle": "2025-05-15T15:15:08.677020Z",
     "shell.execute_reply": "2025-05-15T15:15:08.676407Z",
     "shell.execute_reply.started": "2025-05-15T15:15:08.667374Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU /physical_device:GPU:0\n",
      "['green', 'red', 'nir', 'swir1', 'NDVI', 'MNDWI']\n"
     ]
    }
   ],
   "source": [
    "# General \n",
    "MAPBIOMAS_V    = '10' \n",
    "VERSION        = '4_CONTINENTAL'\n",
    "MOSAIC_VERSION = '1'\n",
    "SAMPLE_VERSION = '4_CONTINENTAL'\n",
    "\n",
    "GOAL_CLASS     = 'aquaculture'\n",
    "GDRIVE         = f'mb{MAPBIOMAS_V}-unet-aquaculture-brazil_'+VERSION\n",
    "\n",
    "FOLDER_TRAIN   = f'mb{MAPBIOMAS_V}_aquaculture_training_samples'\n",
    "FOLDER_TEST    = f'mb{MAPBIOMAS_V}_aquaculture_eval_samples'\n",
    "\n",
    "TRAINING_BASE  = 'training_patches_'+MOSAIC_VERSION+'_v'+SAMPLE_VERSION\n",
    "EVAL_BASE      = 'eval_patches_'+MOSAIC_VERSION+'_v'+SAMPLE_VERSION\n",
    "\n",
    "#Local paths\n",
    "CURRENT_LOCAL_PATH  = f'~/Mapbiomas/modelos/mb{MAPBIOMAS_V}-unet-{GOAL_CLASS}' \n",
    "\n",
    "MODEL_DIR   = f'{CURRENT_LOCAL_PATH}/checkpoint/v{VERSION}'\n",
    "OUTPUT_PATH = CURRENT_LOCAL_PATH+'/output/v'+VERSION\n",
    "create_directory(MODEL_DIR)\n",
    "create_directory(OUTPUT_PATH)\n",
    "\n",
    "\n",
    "# Specify inputs (Landsat bands) to the model and the response variable.\n",
    "opticalBands   = ['green','red','nir','swir1']\n",
    "opticalIndices = ['NDVI','MNDWI']\n",
    "BANDS          = opticalBands + opticalIndices\n",
    "\n",
    "RESPONSE = 'supervised'\n",
    "FEATURES = BANDS + [RESPONSE]\n",
    "\n",
    "# Specify the size and shape of patches expected by the model.\n",
    "KERNEL_SIZE  = 256\n",
    "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
    "COLUMNS = [\n",
    "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
    "]\n",
    "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
    "\n",
    "# Sizes of the training and evaluation datasets.\n",
    "TRAIN_SIZE = 0\n",
    "EVAL_SIZE  = 0\n",
    "\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "DROPOUT   = 0.3\n",
    "EPOCHS    = 50\n",
    "BUFFER_SIZE = 1000\n",
    "OPTIMIZER = 'Nadam' \n",
    "LOSS      = 'BinaryCrossentropy'\n",
    "METRICS   = ['RootMeanSquaredError', 'BinaryIoU']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b056b-2fca-481a-af82-d0b888ff81c5",
   "metadata": {},
   "source": [
    "# MB10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2056915-e816-4dcd-b213-005e7a695e0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T16:29:53.316096Z",
     "iopub.status.busy": "2025-04-30T16:29:53.315809Z",
     "iopub.status.idle": "2025-04-30T16:29:57.023664Z",
     "shell.execute_reply": "2025-04-30T16:29:57.023007Z",
     "shell.execute_reply.started": "2025-04-30T16:29:53.316072Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "''' MB10 '''\n",
    "mosaic_year   = 2023\n",
    "label_version = '4'\n",
    "supervisedImg = ee.Image('projects/solved-mb10/assets/public/LANDSAT/AQUACULTURE/2023-'+label_version+'_CONTINENTAL_SUPERVISEDMASK_FULL').eq(31).unmask(0).rename(RESPONSE);\n",
    "supervisedChannel = supervisedImg.toByte().rename(RESPONSE);\n",
    "image = ee.Image('projects/'+USER_EE_PROJECT+'/assets/USER_PATH/mosaic_'+str(mosaic_year)).addBands(supervisedChannel)\n",
    "mapid = image.getMapId({'bands': ['swir1', 'nir', 'red'], 'min': 30, 'max': 150})\n",
    "\n",
    "\n",
    "trainingPolys = ee.FeatureCollection('projects/solved-mb10/assets/public/LANDSAT/AQUACULTURE/geom_train_TF'+label_version+'_CONTINENTAL_FULL_CONT_LITORAL')\n",
    "evalPolys     = ee.FeatureCollection('projects/solved-mb10/assets/public/LANDSAT/AQUACULTURE/geom_eval_TF'+label_version+'_CONTINENTAL_FULL_CONT_LITORAL')\n",
    "\n",
    "print(trainingPolys.size().getInfo())\n",
    "print(evalPolys.size().getInfo())\n",
    "polyImage  = ee.Image(0).byte().paint(trainingPolys, 1).paint(evalPolys, 2)\n",
    "polyImage  = polyImage.updateMask(polyImage)\n",
    "mapidGeoms = polyImage.getMapId({'min': 1, 'max': 2, 'palette': ['red', 'blue']})\n",
    "\n",
    "# map = folium.Map(location=[-1.3621, -45.2738], zoom_start=5)\n",
    "# map = folium.Map(location=[-5.9442, -56.5265])\n",
    "map = folium.Map()\n",
    "folium.TileLayer(\n",
    "    tiles=mapid['tile_fetcher'].url_format,\n",
    "    attr='Planet',\n",
    "    overlay=True,\n",
    "    name='Mosaic composite',\n",
    "  ).add_to(map)\n",
    "\n",
    "mapid = supervisedChannel.select(RESPONSE).selfMask().getMapId({'min': 0, 'max': 1, 'pallete':'#ff0000'})\n",
    "\n",
    "folium.TileLayer(\n",
    "    tiles=mapid['tile_fetcher'].url_format,\n",
    "    attr='Google Earth Engine',\n",
    "    overlay=True,\n",
    "    name='supervisedLayer',\n",
    "  ).add_to(map)\n",
    "\n",
    "folium.TileLayer(\n",
    "    tiles=mapidGeoms['tile_fetcher'].url_format,\n",
    "    attr='Google Earth Engine',\n",
    "    overlay=True,\n",
    "    name='polygons',\n",
    "  ).add_to(map)\n",
    "\n",
    "map.add_child(folium.LayerControl())\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7392b454-0219-4bb1-9dc1-6b9c39e1235e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T16:30:00.238395Z",
     "iopub.status.busy": "2025-04-30T16:30:00.238121Z",
     "iopub.status.idle": "2025-04-30T16:30:00.243709Z",
     "shell.execute_reply": "2025-04-30T16:30:00.243054Z",
     "shell.execute_reply.started": "2025-04-30T16:30:00.238371Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "featureStack = ee.Image.cat([\n",
    "  image.select(BANDS).unmask(0),\n",
    "  image.select(RESPONSE).unmask(0)\n",
    "]).float()\n",
    "\n",
    "list = ee.List.repeat(1, KERNEL_SIZE)\n",
    "lists = ee.List.repeat(list, KERNEL_SIZE)\n",
    "kernel = ee.Kernel.fixed(KERNEL_SIZE, KERNEL_SIZE, lists)\n",
    "\n",
    "arrays = featureStack.neighborhoodToArray(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15cbc66-d51f-4473-a7a0-f15844dafa0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T16:30:17.498160Z",
     "iopub.status.busy": "2025-04-30T16:30:17.497869Z",
     "iopub.status.idle": "2025-04-30T16:30:18.173585Z",
     "shell.execute_reply": "2025-04-30T16:30:18.172902Z",
     "shell.execute_reply.started": "2025-04-30T16:30:17.498136Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:65400\n",
      "EVAL:16400\n"
     ]
    }
   ],
   "source": [
    "# Convert the feature collections to lists for iteration.\n",
    "trainingPolysList = trainingPolys.toList(trainingPolys.size())\n",
    "evalPolysList = evalPolys.toList(evalPolys.size())\n",
    "# These numbers determined experimentally.\n",
    "n = 20 # Number of shards in each polygon.\n",
    "N = 200 # Total sample size in each polygon.\n",
    "\n",
    "#Add some generalism\n",
    "TRAIN_SIZE = trainingPolys.size().getInfo()*N\n",
    "EVAL_SIZE = evalPolys.size().getInfo()*N\n",
    "print('TRAIN:'+str(TRAIN_SIZE))\n",
    "print('EVAL:'+str(EVAL_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcde065-8448-4f55-b0b8-8984aa1d3dfd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Train/Test Chips Exportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a6fb5b-e430-485a-b762-f3582ec1db10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T16:31:34.687030Z",
     "iopub.status.busy": "2025-04-30T16:31:34.686742Z",
     "iopub.status.idle": "2025-04-30T16:33:59.993603Z",
     "shell.execute_reply": "2025-04-30T16:33:59.993049Z",
     "shell.execute_reply.started": "2025-04-30T16:31:34.687006Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:65400\n",
      "EVAL:16400\n"
     ]
    }
   ],
   "source": [
    "# Convert the feature collections to lists for iteration.\n",
    "trainingPolysList = trainingPolys.toList(trainingPolys.size())\n",
    "evalPolysList = evalPolys.toList(evalPolys.size())\n",
    "# These numbers determined experimentally.\n",
    "n = 20 # Number of shards in each polygon.\n",
    "N = 200 # Total sample size in each polygon.\n",
    "\n",
    "#Add some generalism\n",
    "TRAIN_SIZE = trainingPolys.size().getInfo()*N\n",
    "EVAL_SIZE = evalPolys.size().getInfo()*N\n",
    "print('TRAIN:'+str(TRAIN_SIZE))\n",
    "print('EVAL:'+str(EVAL_SIZE))\n",
    "\n",
    "# Export all the training data (in many pieces), with one task \n",
    "# per geometry.\n",
    "for g in range(trainingPolys.size().getInfo()):\n",
    "  geomSample = ee.FeatureCollection([])\n",
    "  for i in range(n):\n",
    "    sample = arrays.sample(\n",
    "      region = ee.Feature(trainingPolysList.get(g)).geometry(), \n",
    "      scale = 30, \n",
    "      numPixels = N / n, # Size of the shard.\n",
    "      seed = i,\n",
    "      tileScale = 8\n",
    "    )\n",
    "    geomSample = geomSample.merge(sample)\n",
    "  \n",
    "  desc = TRAINING_BASE + '_g' + str(g)\n",
    "  task = ee.batch.Export.table.toDrive(\n",
    "    collection = geomSample,\n",
    "    description = desc, \n",
    "    folder = GDRIVE+'/'+FOLDER_TRAIN, \n",
    "    fileNamePrefix = desc,\n",
    "    fileFormat = 'TFRecord',\n",
    "    selectors = BANDS + [RESPONSE]\n",
    "  )\n",
    "  task.start()\n",
    "\n",
    "# Export all the evaluation data.\n",
    "for g in range(evalPolys.size().getInfo()):\n",
    "  geomSample = ee.FeatureCollection([])\n",
    "  for i in range(n):\n",
    "    sample = arrays.sample(\n",
    "      region = ee.Feature(evalPolysList.get(g)).geometry(), \n",
    "      scale = 30, \n",
    "      numPixels = N / n,\n",
    "      seed = i,\n",
    "      tileScale = 8\n",
    "    )\n",
    "    geomSample = geomSample.merge(sample)\n",
    "  \n",
    "  desc = EVAL_BASE + '_g' + str(g)\n",
    "  task = ee.batch.Export.table.toDrive(\n",
    "    collection = geomSample,\n",
    "    description = desc, \n",
    "    folder = GDRIVE+'/'+FOLDER_TEST, \n",
    "    fileNamePrefix = desc,\n",
    "    fileFormat = 'TFRecord',\n",
    "    selectors = BANDS + [RESPONSE],\n",
    "  )\n",
    "  task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b5b575-9da1-41ce-878d-8fa8973835bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T01:31:38.272277Z",
     "iopub.status.busy": "2025-05-02T01:31:38.271684Z",
     "iopub.status.idle": "2025-05-02T01:31:38.679954Z",
     "shell.execute_reply": "2025-05-02T01:31:38.679329Z",
     "shell.execute_reply.started": "2025-05-02T01:31:38.272251Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_tfrecord(example_proto):\n",
    "  \"\"\"The parsing function.\n",
    "  Read a serialized example into the structure defined by FEATURES_DICT.\n",
    "  Args:\n",
    "    example_proto: a serialized Example.\n",
    "  Returns: \n",
    "    A dictionary of tensors, keyed by feature name.\n",
    "  \"\"\"\n",
    "  print(FEATURES_DICT)\n",
    "  return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
    "\n",
    "\n",
    "def to_tuple(inputs):\n",
    "  \"\"\"Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n",
    "  Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n",
    "  Args:\n",
    "    inputs: A dictionary of tensors, keyed by feature name.\n",
    "  Returns: \n",
    "    A dtuple of (inputs, outputs).\n",
    "  \"\"\"\n",
    "  inputsList = [inputs.get(key) for key in FEATURES]\n",
    "  stacked = tf.stack(inputsList, axis=0)\n",
    "  # Convert from CHW to HWC\n",
    "  stacked = tf.transpose(stacked, [1, 2, 0])\n",
    "  return stacked[:,:,:len(BANDS)], stacked[:,:,len(BANDS):]\n",
    "\n",
    "\n",
    "def get_dataset(pattern):\n",
    "  \"\"\"Function to read, parse and format to tuple a set of input tfrecord files.\n",
    "  Get all the files matching the pattern, parse and convert to tuple.\n",
    "  Args:\n",
    "    pattern: A file pattern to match in a Cloud Storage bucket.\n",
    "  Returns: \n",
    "    A tf.data.Dataset\n",
    "  \"\"\"\n",
    "  glob = tf.io.gfile.glob(pattern)\n",
    "  dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
    "  dataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
    "  dataset = dataset.map(to_tuple, num_parallel_calls=5)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413411d9-c828-4457-8481-0be6000c423e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T01:55:54.426185Z",
     "iopub.status.busy": "2025-05-02T01:55:54.425891Z",
     "iopub.status.idle": "2025-05-02T01:55:54.476751Z",
     "shell.execute_reply": "2025-05-02T01:55:54.476134Z",
     "shell.execute_reply.started": "2025-05-02T01:55:54.426160Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_training_dataset():\n",
    "    \"\"\"Get the preprocessed training dataset\n",
    "    Returns: \n",
    "    A tf.data.Dataset of training data.\n",
    "    \"\"\"\n",
    "    glob = CURRENT_LOCAL_PATH+'/train/'+'v'+SAMPLE_VERSION+'/' + TRAINING_BASE + '*'\n",
    "    dataset = get_dataset(glob)\n",
    "    # FOR COMPUTATION OF TOTAL INSTANCES\n",
    "    # train_size = dataset.reduce(np.int64(0), lambda x,_ : x + 1).numpy()\n",
    "    # print(train_size)\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE, reshuffle_each_iteration=True).batch(BATCH_SIZE).repeat()\n",
    "    return dataset\n",
    "\n",
    "training = get_training_dataset()\n",
    "print(training.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ef8b20-e422-4fc8-8f32-f62a9e7b380e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T01:56:50.651400Z",
     "iopub.status.busy": "2025-05-02T01:56:50.651106Z",
     "iopub.status.idle": "2025-05-02T01:56:50.698063Z",
     "shell.execute_reply": "2025-05-02T01:56:50.697245Z",
     "shell.execute_reply.started": "2025-05-02T01:56:50.651376Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_eval_dataset():\n",
    "    # EVAL_BASE = 'eval_patches_1'\n",
    "    print(EVAL_BASE)\n",
    "    glob      = CURRENT_LOCAL_PATH+'/eval/'+'v'+SAMPLE_VERSION+'/' + EVAL_BASE + '*'\n",
    "    dataset   = get_dataset(glob)\n",
    "    # FOR COMPUTATION OF TOTAL INSTANCES\n",
    "    # eval_size = dataset.reduce(np.int64(0), lambda x,_ : x + 1).numpy()\n",
    "    # print(eval_size)\n",
    "    dataset = dataset.batch(1).repeat()\n",
    "    return dataset\n",
    "\n",
    "evaluation = get_eval_dataset()\n",
    "print(evaluation.take(1))\n",
    "# print(iter(evaluation.take(1)).next())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b905466-9637-40b1-a030-6624f28cb52b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4e7438-4903-4eb1-a7c6-2673a9bd7775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T15:15:12.712853Z",
     "iopub.status.busy": "2025-05-15T15:15:12.712412Z",
     "iopub.status.idle": "2025-05-15T15:15:12.740347Z",
     "shell.execute_reply": "2025-05-15T15:15:12.739812Z",
     "shell.execute_reply.started": "2025-05-15T15:15:12.712826Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, num_filters):\n",
    "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
    "\tencoder = layers.BatchNormalization()(encoder)\n",
    "\tencoder = layers.Activation('relu')(encoder)\n",
    "\tencoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
    "\tencoder = layers.BatchNormalization()(encoder)\n",
    "\tencoder = layers.Activation('relu')(encoder)\n",
    "\treturn encoder\n",
    "\n",
    "def encoder_block(input_tensor, num_filters):\n",
    "\tencoder = conv_block(input_tensor, num_filters)\n",
    "\tencoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
    "\treturn encoder_pool, encoder\n",
    "\n",
    "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
    "\tdecoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
    "\tdecoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
    "\tdecoder = layers.BatchNormalization()(decoder)\n",
    "\tdecoder = layers.Activation('relu')(decoder)\n",
    "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "\tdecoder = layers.BatchNormalization()(decoder)\n",
    "\tdecoder = layers.Activation('relu')(decoder)\n",
    "\tdecoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "\tdecoder = layers.BatchNormalization()(decoder)\n",
    "\tdecoder = layers.Activation('relu')(decoder)\n",
    "\treturn decoder\n",
    "\n",
    "def get_model():\n",
    "\t\"\"\"Generates the NN arquitecture\"\"\"\n",
    "\tinputs = layers.Input(shape=[None, None, len(BANDS)])\n",
    "\tencoder0_pool, encoder0 = encoder_block(inputs, 64)\n",
    "\tencoder1_pool, encoder1 = encoder_block(encoder0_pool, 128)\n",
    "\tencoder2_pool, encoder2 = encoder_block(encoder1_pool, 256)\n",
    "\tencoder3_pool, encoder3 = encoder_block(encoder2_pool, 512)\n",
    "\tcenter = conv_block(encoder3_pool, 1024)\n",
    "\tdecoder4 = decoder_block(center, encoder3, 512)\n",
    "\tdecoder3 = decoder_block(decoder4, encoder2, 256)\n",
    "\tdecoder2 = decoder_block(decoder3, encoder1, 128)\n",
    "\tdecoder1 = decoder_block(decoder2, encoder0, 64)\n",
    "\tdropout = layers.Dropout(DROPOUT, name=\"dropout\", noise_shape=None, seed=None)(decoder1)\n",
    "\toutputs = layers.Conv2D(1, (1, 1),  activation=tf.nn.sigmoid, padding='same', kernel_initializer=tf.keras.initializers.GlorotNormal())(dropout)\n",
    "\tmodel = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "\toptimizer = tf.keras.optimizers.Nadam( 0.000005, name='optimizer')\n",
    "\n",
    "\tmodel.compile(\n",
    "\t\toptimizer=optimizer, \n",
    "\t\tloss=losses.get(LOSS),\n",
    "\t\tmetrics=[metrics.get(metric) for metric in METRICS]\n",
    "    )\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c687c0e4-5db1-4ebb-84aa-52e633a03964",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T15:15:17.752471Z",
     "iopub.status.busy": "2025-05-15T15:15:17.752182Z",
     "iopub.status.idle": "2025-05-15T15:15:42.605946Z",
     "shell.execute_reply": "2025-05-15T15:15:42.605446Z",
     "shell.execute_reply.started": "2025-05-15T15:15:17.752447Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "loaded_model = get_model()\n",
    "EPOCH = 0\n",
    "if EPOCH>0:\n",
    "    LOADED_MODEL_DIR = f'{MODEL_DIR}/cp-00{str(EPOCH)}.keras'\n",
    "    loaded_model.load_weights(LOADED_MODEL_DIR)\n",
    "print(loaded_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfe22f2-a4a5-45bf-89a2-e2af9e1af71f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T01:33:08.382580Z",
     "iopub.status.busy": "2025-05-02T01:33:08.382254Z",
     "iopub.status.idle": "2025-05-02T01:33:08.388632Z",
     "shell.execute_reply": "2025-05-02T01:33:08.388070Z",
     "shell.execute_reply.started": "2025-05-02T01:33:08.382559Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def previewClass(epoch,log):\n",
    "    \"\"\"Callback funtion for training acompaniment by visual verification\"\"\"\n",
    "    counter = 0\n",
    "    for batch in evaluation.shuffle(1000).take(3):\n",
    "        pureImage = batch[0]\n",
    "        supervised = batch[1]\n",
    "        stacked = tf.transpose(pureImage[0], [0, 1, 2]).numpy()\n",
    "        stackedS = tf.transpose(supervised[0], [0, 1, 2]).numpy()\n",
    "\n",
    "        test_pred_raw = loaded_model.predict(pureImage)\n",
    "        test_pred_raw = tf.transpose(test_pred_raw[0],[0, 1, 2]).numpy()\n",
    "        fig = plt.figure(figsize=[12,4])\n",
    "        # show original image\n",
    "        fig.add_subplot(131)\n",
    "        plt.imshow(stacked[:,:,0:3].astype(np.uint8), interpolation='nearest', vmin=0, vmax=255)\n",
    "        fig.add_subplot(132)\n",
    "        plt.imshow(stackedS[:,:,0], interpolation='nearest',cmap=\"gray\")\n",
    "        fig.add_subplot(133)\n",
    "        plt.imshow(test_pred_raw[:,:,0], interpolation='nearest',cmap=\"gray\")\n",
    "        plt.show()\n",
    "        counter = counter+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db056586-7287-4090-a4a9-6fa5504cec52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T17:34:54.437696Z",
     "iopub.status.busy": "2025-05-02T17:34:54.437301Z",
     "iopub.status.idle": "2025-05-02T19:32:59.704454Z",
     "shell.execute_reply": "2025-05-02T19:32:59.703722Z",
     "shell.execute_reply.started": "2025-05-02T17:34:54.437662Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "checkpoint_path = MODEL_DIR+\"/cp-{epoch:04d}.keras\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "create_directory(checkpoint_dir)\n",
    "print(checkpoint_dir)\n",
    "\n",
    "\n",
    "n = 20 # Number of shards in each polygon.\n",
    "N = 200 # Total sample size in each polygon.\n",
    "TRAIN_SIZE = trainingPolys.size().getInfo()*N\n",
    "EVAL_SIZE = evalPolys.size().getInfo()*N\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=f'output/v{VERSION}/log_model',write_images=True)\n",
    "cp_callback  = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,verbose=1, save_weights_only=False,save_best_only=False,save_freq='epoch')\n",
    "img_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=previewClass)\n",
    "earlyStopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "\n",
    "\n",
    "result = loaded_model.fit(x=training,\n",
    "  epochs=80,\n",
    "  initial_epoch=0, # REMEMBER TO CHANGE THIS INITIAL EPOCH PARAM, WHEN OTHER MODEL HAS BEEN LOADED\n",
    "  steps_per_epoch=int(TRAIN_SIZE / BATCH_SIZE),\n",
    "  verbose=1,\n",
    "  shuffle=True,\n",
    "  validation_data=evaluation,\n",
    "  validation_steps=EVAL_SIZE,\n",
    "  callbacks = [cp_callback,img_callback,tensorboard,earlyStopping_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29146e05",
   "metadata": {},
   "source": [
    "# Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ca594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather Grid\n",
    "kernel_buffer   = [256, 256]\n",
    "\n",
    "ROOT_PATH      = './'\n",
    "MOSAIC_VERSION = '1'\n",
    "mosaic_scale   = 30\n",
    "GRID_IDs       = pygeoj.load(f'{ROOT_PATH}/GRIDS/GRID-ALLCALSSES-COL9.geojson')\n",
    "GRID           = pygeoj.load(f'{ROOT_PATH}/GRIDS/GRID-ALLCALSSES-COL9-STACK.geojson')\n",
    "\n",
    "\n",
    "reduced_grid = [int(geo.properties['id']) for geo in GRID if geo.properties['aqua'] == 1]\n",
    "reduced_grid.sort()\n",
    "grids_from_mb8 = [1723,1773,1822,2127,2177,2178,2224,2227,2271,2307,2318,2322,2513,838,1672,1720,1823,2128,2256,2270,2272,2273,2274,2308,2517,2517]\n",
    "full_aqua = reduced_grid+grids_from_mb8\n",
    "full_aqua_regions = [int(geo.properties['id']) for geo in GRID if geo.properties['id'] in full_aqua]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5c6c4",
   "metadata": {},
   "source": [
    "# Export mosaics to GDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aa8cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doExport(out_image_base,year,region_id, kernel_buffer, roi):\n",
    "  \"\"\"Run the image export task.\"\"\"\n",
    "  image = ee.Image('projects/'+USER_EE_PROJECT+'/assets/USER_PATH/mosaic_'+str(year))\n",
    "  # Export the image, specifying scale and region.\n",
    "  task = ee.batch.Export.image.toDrive(\n",
    "    image          = image.select(BANDS).toFloat(),\n",
    "    description    = out_image_base+'_'+str(year),\n",
    "    fileNamePrefix = out_image_base+'_'+str(year), \n",
    "    folder         = 'mosaics_landsat/'+str(year),\n",
    "    scale          = 30,\n",
    "    region         = roi,\n",
    "    fileFormat     = 'GEOTIFF',\n",
    "    formatOptions  = { \n",
    "      'patchDimensions': KERNEL_SHAPE,\n",
    "      'kernelSize': kernel_buffer,\n",
    "      'compressed': True,\n",
    "      'maxFileSize': 157286400\n",
    "    }\n",
    "  )\n",
    "  task.start()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66132bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the export.\n",
    "for region in full_aqua_regions:\n",
    "    region_id = int(region.properties['id'])\n",
    "    image_base_name =f'v{MOSAIC_VERSION}_L9_grid_{region_id}'\n",
    "    if int(region_id):\n",
    "      print('Region:',int(region_id))\n",
    "      for y in range(1985, 2021): \n",
    "          doExport(image_base_name,y, kernel_buffer, region.geometry.coordinates[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba3ab3-9036-4957-9f13-b7c086b01f9a",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d29a617-1465-4f33-ba1c-25c498f2790d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T15:15:42.607053Z",
     "iopub.status.busy": "2025-05-15T15:15:42.606864Z",
     "iopub.status.idle": "2025-05-15T15:15:43.065790Z",
     "shell.execute_reply": "2025-05-15T15:15:43.065203Z",
     "shell.execute_reply.started": "2025-05-15T15:15:42.607038Z"
    }
   },
   "outputs": [],
   "source": [
    "def mosaic_predict(mosaic_lzw,year, region_id, output_path, version, kernel_dim, optical_bands, optical_indices, model, mosaic_scale, EPOCH):\n",
    "    \"\"\"Executes segmentation over mosaic data exported from EE as .geotiff\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mosaic_lzw : geotiff\n",
    "        Geotiff data representing the LANDSAT mosaic. The region exported must be the same as the region_id\n",
    "    year : int\n",
    "        The year of said geotiff\n",
    "    region_id : int\n",
    "        The id of the geojson grid that identifies the geotiff region\n",
    "    output_path: str\n",
    "        The output path for the segmented data\n",
    "    version: int\n",
    "        The segmentation version\n",
    "    kernel_dim: int\n",
    "        The dimention of the patches to be segmented\n",
    "    optical_bands: list\n",
    "        List of optical bands present on each geotiff\n",
    "    optical_indices: list\n",
    "        List of optical indices on each geotiff\n",
    "    model: Tensorflow model\n",
    "        The model trained\n",
    "    mosaic_scale: int\n",
    "        The scale of the geotiff. Tipically, for landsat the scale is 30\n",
    "    EPOCH: int\n",
    "        The epoch of training for the model. For identification\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Geotiff\n",
    "        A geotiff corresonding to the segmentation fo the target for the mosaic_lzw\n",
    "    \"\"\"\n",
    "\n",
    "    paths_to_check = [\n",
    "        f'{output_path}/{year}/e{EPOCH}/outimage_v{version}_e{EPOCH}_grid_{region_id}_{year}_lzw.tif',\n",
    "        f'{output_path}/{year}/e{EPOCH}/outimage_v{version}_e{EPOCH}_grid_{region_id}_{year}_byte_lzw.tif',\n",
    "    ]\n",
    "    if check_file_exists(paths_to_check):\n",
    "        return f'GRID {region_id} already predicted'\n",
    "\n",
    "    with rasterio.open(mosaic_lzw, 'r') as ds:\n",
    "        arr = ds.read()\n",
    "\n",
    "    arr = np.clip(arr, 0, None)\n",
    "    img_arr_original = arr.astype(np.float32)\n",
    "\n",
    "    if img_arr_original.shape[0]> 6:\n",
    "        img_arr_original = img_arr_original[1:, :, :] # delete blue band\n",
    "    img_arr_original = np.nan_to_num(img_arr_original, nan=0.0) \n",
    "    print(f'ORIGINAL SHAPE: {img_arr_original.shape}')\n",
    "    \n",
    "    ''' MAKE THE IMAGE QUADRATIC '''\n",
    "    arr_shape_xy = np.array(img_arr_original.shape[1:])\n",
    "    min_dim = arr_shape_xy.min()\n",
    "    index_min_dim = np.where(arr_shape_xy==min_dim)[0][0]\n",
    "    if index_min_dim == 0: # [len(bands), x, y], x<y\n",
    "        img_arr = img_arr_original[:, :, :min_dim] \n",
    "    elif index_min_dim ==1:  # [len(bands), x, y], x>y\n",
    "        img_arr = img_arr_original[:, :min_dim, :]\n",
    "    \n",
    "    ''' ENSURE IMAGE DIMENSIONS ARE MULTIPLES OF kernel_dim '''\n",
    "    \n",
    "    pad_size = (kernel_dim - (min_dim % kernel_dim)) % kernel_dim\n",
    "    \n",
    "    if pad_size > 0:\n",
    "        img_arr = np.pad(img_arr, ((0, 0), (0, pad_size), (0, pad_size)), mode='mean') # Pads with the edge values of array.\n",
    "\n",
    "    disired_dims    = kernel_dim*2 \n",
    "    bands           = optical_bands + optical_indices\n",
    "    patches         = patchify(img_arr, (len(bands), disired_dims, disired_dims), step=kernel_dim)\n",
    "    dim             = patches.shape[1]\n",
    "    patch2          = patches.reshape((1, dim**2, len(bands), disired_dims, disired_dims))\n",
    "    patch2_reshaped = patch2[0].reshape((dim**2, len(bands), disired_dims, disired_dims))\n",
    "    patch3          = np.transpose(patch2_reshaped, [0,2,3,1])\n",
    "\n",
    "    curr_patch      = tf.data.Dataset.from_tensor_slices(patch3).batch(1)\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        predictions_arr = model.predict(curr_patch, batch_size=8,steps=None, verbose=1)\n",
    "    patchesPerRow  = dim\n",
    "    TotalPatches   = dim**2\n",
    "    patchDimension = [disired_dims,disired_dims]\n",
    "\n",
    "    counter       = 1\n",
    "    rowCounter    = 1\n",
    "    globalCounter = 0\n",
    "    finalArray    = np.array([])\n",
    "    rowArray      = np.array([])\n",
    "\n",
    "    for raw_record in predictions_arr:\n",
    "        raw_record = np.squeeze(raw_record)\n",
    "        rows,cols = raw_record.shape\n",
    "\n",
    "        limite_esquerda = kernel_dim//2\n",
    "        limite_direita  = kernel_dim + (kernel_dim//2)\n",
    "        limite_inferior = kernel_dim + (kernel_dim//2)\n",
    "        limite_superior = kernel_dim//2\n",
    "        if rowCounter == 1: # FIRST ROW\n",
    "            limite_superior = 0 \n",
    "        if (counter == 1) or (counter == patchesPerRow+1): # FIRST COLUMN\n",
    "            limite_esquerda = 0\n",
    "        if (counter == patchesPerRow+1) and rowCounter == 1: # FIRST COLUMNS ON SECUND ROW\n",
    "            limite_superior = kernel_dim//2  \n",
    "\n",
    "        if counter == patchesPerRow:  # LAST COLUMN\n",
    "            limite_direita = kernel_dim * 2 \n",
    "\n",
    "        if rowCounter == (TotalPatches/patchesPerRow) or (rowCounter == (TotalPatches/patchesPerRow)-1 and counter == patchesPerRow+1):  # LAST ROW\n",
    "            limite_inferior = kernel_dim * 2\n",
    "        raw_record = raw_record[limite_superior:limite_inferior,limite_esquerda:limite_direita]\n",
    "        if rowCounter == 1:\n",
    "            finalArray = rowArray\n",
    "        if counter <= patchesPerRow:\n",
    "            if counter == 1:\n",
    "                rowArray = raw_record\n",
    "            else:\n",
    "                rowArray = np.concatenate((rowArray,raw_record), axis = 1)\n",
    "            counter = counter+1\n",
    "        else:\n",
    "            counter = 2\n",
    "            rowCounter = rowCounter+1\n",
    "            if np.array_equal(finalArray,rowArray):\n",
    "                finalArray = rowArray\n",
    "            else:\n",
    "                finalArray = np.concatenate((finalArray,rowArray),axis=0)\n",
    "            rowArray = raw_record\n",
    "        globalCounter = globalCounter+1\n",
    "    finalArray = np.concatenate((finalArray,rowArray),axis=0)\n",
    "\n",
    "\n",
    "    finalArray_padded = dynamic_slice_or_pad(arr_shape_xy, finalArray)\n",
    "    print(f'finalArray_padded: {finalArray_padded.shape}\\n\\n')\n",
    "    \n",
    "    rows,cols = finalArray_padded.shape\n",
    "    finalArray_padded = np.array([finalArray_padded]) \n",
    "\n",
    "    output_path = f'{output_path}/{year}/e{EPOCH}'\n",
    "    create_directory(output_path)\n",
    "    raster_uri     = output_path + '/UNET_v'+version+'grid'+str(region_id)+'_'+str(year)+'.tif'\n",
    "    try:\n",
    "        if not np.any(np.isnan(finalArray_padded)):\n",
    "            finalArray_padded = np.round((finalArray_padded.astype(np.float32))*255).astype(np.uint8)\n",
    "        raster_uri_lzw = f'{output_path}/outimage_v{version}_e{EPOCH}_grid_'+str(region_id)+'_'+str(year)+'_byte_lzw.tif'\n",
    "        data_type = \"uint8\"\n",
    "    except Exception as inst:\n",
    "        print(f'ERROR: For grid {region_id} \\n {inst.args}, {inst}\\n Raster in float')\n",
    "        raster_uri_lzw = f'{output_path}/outimage_v{version}_e{EPOCH}_grid_'+str(region_id)+'_'+str(year)+'_float_lzw.tif'\n",
    "        data_type = \"float32\"  \n",
    "    \n",
    "\n",
    "    with rasterio.open(raster_uri,'w',\n",
    "                  driver=\"GTiff\",\n",
    "                  height=rows,\n",
    "                  width=cols,\n",
    "                  count=1,\n",
    "                  dtype=data_type,\n",
    "                  crs='EPSG:4326',\n",
    "                  transform=ds.transform,\n",
    "                  nodata=0) as dataset:\n",
    "                      dataset.write(finalArray_padded)\n",
    "    dataset = gdal.Open(raster_uri, gdal.GA_Update)\n",
    "    !gdal_translate -of GTiff -ot Byte -co \"COMPRESS=LZW\" -co \"PREDICTOR=2\" -co \"TILED=YES\" {raster_uri} {raster_uri_lzw} \n",
    "    !rm {raster_uri}\n",
    "    print(\"C'est finiz\\n\\n\")\n",
    "    return f'GRID {region_id} predito'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aee0320-e014-4592-ad2e-732c7fb91451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T15:15:44.892092Z",
     "iopub.status.busy": "2025-05-15T15:15:44.891809Z",
     "iopub.status.idle": "2025-05-15T15:15:44.898476Z",
     "shell.execute_reply": "2025-05-15T15:15:44.897818Z",
     "shell.execute_reply.started": "2025-05-15T15:15:44.892068Z"
    }
   },
   "outputs": [],
   "source": [
    "def dynamic_slice_or_pad(target_shape, predicted_img):\n",
    "\n",
    "    \"\"\"Add padding to the segmentation output so that it mayches the mosaic geotiff input dimentions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target_shape : list\n",
    "        List with the size of total rows and columns of the input image\n",
    "    predicted_img : Numpy array\n",
    "        Array repreenting the segmented output\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Numpy array\n",
    "        Numpy array representing the segmentation output properly padded\n",
    "    \"\"\"\n",
    "    target_rows, target_cols = target_shape\n",
    "    pad_rows = target_rows - predicted_img.shape[0]\n",
    "    pad_cols = target_cols - predicted_img.shape[1]\n",
    "\n",
    "    if pad_rows < 0:\n",
    "        predicted_img = predicted_img[:target_rows, :]\n",
    "    elif pad_rows > 0:\n",
    "        predicted_img = np.pad(predicted_img, ((0, pad_rows), (0, 0)), mode='constant')\n",
    "\n",
    "    if pad_cols < 0:\n",
    "        predicted_img = predicted_img[:, :target_cols]\n",
    "    elif pad_cols > 0:\n",
    "        predicted_img = np.pad(predicted_img, ((0, 0), (0, pad_cols)), mode='constant')\n",
    "    \n",
    "    return predicted_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30f4c8-670e-4319-a480-db36d10368fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T19:36:12.405785Z",
     "iopub.status.busy": "2025-05-15T19:36:12.405496Z",
     "iopub.status.idle": "2025-05-15T19:36:14.005994Z",
     "shell.execute_reply": "2025-05-15T19:36:14.005497Z",
     "shell.execute_reply.started": "2025-05-15T19:36:12.405761Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prediction iteration\n",
    "start = time.time()\n",
    "for year in range(1985,2024):\n",
    "    full_aqua_ = full_aqua\n",
    "    if year == 2023:\n",
    "        full_aqua_ = [int(n + 1) for n in full_aqua]\n",
    "\n",
    "    print(f'/n/nYEAR:{year}')\n",
    "    i = 0\n",
    "    add_list=[]\n",
    "    for region_id in full_aqua_:\n",
    "        print(f'REGION ID {region_id}')\n",
    "        tf.keras.backend.clear_session()\n",
    "        start = time.time()\n",
    "        \n",
    "        try:\n",
    "            MOSAIC_PATH    = f'{ROOT_PATH}/mosaico_landsat/{year}'\n",
    "            search_pattern = os.path.join(MOSAIC_PATH, f'v{MOSAIC_VERSION}_L*_grid_{region_id}_{year}*.tif')\n",
    "            matching_files = glob.glob(search_pattern)\n",
    "           \n",
    "            if matching_files:\n",
    "                i = i+1\n",
    "                region_mosaic_file = matching_files[0]\n",
    "                str_return = mosaic_predict(region_mosaic_file, year, region_id, OUTPUT_PATH, VERSION, KERNEL_SIZE, opticalBands, opticalIndices, loaded_model, mosaic_scale, 64)\n",
    "                print(str_return)\n",
    "            else:\n",
    "                print(i)\n",
    "                logging.error(\"No matching:\",search_pattern)\n",
    "                add_list.append(region_id)\n",
    "                print(\"No matching:\",search_pattern)\n",
    "        except Exception as e:\n",
    "            add_list.append(region_id)\n",
    "            logging.error(\"The error from mosaic_predict is: \",e)\n",
    "end = time.time()\n",
    "print(add_list)\n",
    "print('Prediction Time per year = '+str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8028b351-e3f4-4db8-8aef-58dae9eec5bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T19:26:57.486461Z",
     "iopub.status.busy": "2025-05-15T19:26:57.486163Z",
     "iopub.status.idle": "2025-05-15T19:29:39.955962Z",
     "shell.execute_reply": "2025-05-15T19:29:39.955278Z",
     "shell.execute_reply.started": "2025-05-15T19:26:57.486437Z"
    }
   },
   "outputs": [],
   "source": [
    "# Image reprojection and warping utility\n",
    "for year_ in range(2024,2025):\n",
    "    input_imgs = f'{OUTPUT_PATH}/{year_}/e{EPOCH}/outimage_v{VERSION}*.tif'\n",
    "    output  = f'{OUTPUT_PATH}/{year_}/e{EPOCH}/{year_}_v{VERSION}_e{EPOCH}.tif'\n",
    "    !gdalwarp  -r average -multi -wo NUM_THREADS=50 -co TILED=YES -co NUM_THREADS=62 -t_srs EPSG:4326 {input_imgs} {output} -of GTiff -ot Byte  -co COMPRESS=DEFLATE -co PREDICTOR=2 -co ZLEVEL=9  -overwrite -quiet --config GDAL_CACHEMAX 2500 -wm 2500 -co BIGTIFF=YES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ead1b95f633dc9c51826328e1846203f51a198c6fb5f2884a80417ba131d4e82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
